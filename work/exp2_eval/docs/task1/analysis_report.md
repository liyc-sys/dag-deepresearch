# DAG-DeepResearch 评测分析报告

## 1. 评测结果对比

| 模型 | 数据集 | DAG框架 | SWALM基线 | 差值 | 样本数 |
|------|--------|---------|-----------|------|--------|
| seed18 | BrowseComp EN | **28.0%** | 81.0% | -53% | 50 |
| seed18 | BrowseComp ZH | **21.7%** | 70.0% | -48% | 23 |
| seed18 | DeepSearchQA | 评测中... | 46.5% | TBD | 50 |

**结论**：DAG-DeepResearch 在 BrowseComp 任务上的表现远不及 SWALM，仅约为 SWALM 的 1/3。

---

## 2. 慢的根本原因分析

| 指标 | 数值 |
|------|------|
| 每题平均步数 | 31.9 步 |
| 每题平均搜索次数 | **49次**（最多109次！） |
| 每题平均 input tokens | ~83万（bc_en）/ ~64万（bc_zh） |
| 每题平均耗时 | **18.8分钟** |
| 总 50题耗时 | ~3.3小时 |

**核心原因**：每次 LLM 调用时 context 中包含了所有历史搜索结果，随步骤线性增长。到 Step 40 时，input token 已达 100万+，每次推理需要几十秒。

**对比 SWALM**：SWALM 使用 `CascadedFIFOCondenser`（max_queue_length=20条历史），严格压缩 context，每步 token 消耗远低于 DAG-DeepResearch。

---

## 3. 失败模式深度分析

### 3.1 错误类型分布（bc_en，36个错误中）

| 类型 | 数量 | 比例 |
|------|------|------|
| 找到答案但答错（confident wrong） | 29 | 80.6% |
| 完全未找到答案（NO_ANSWER） | 7 | 19.4% |

**bc_zh 100% 的错误都是"找到但答错"**，没有 NO_ANSWER 情况，说明中文搜索对中文问题能找到一些内容，但准确度极差。

### 3.2 步数与准确性的关系

| 组别 | 平均步数 |
|------|---------|
| 正确 case | 21.3 步 |
| 错误 case | 36.0 步 |

**反直觉发现**：步数越多反而越容易出错。这说明当模型在较少步数内找到正确答案时（靠好的运气或精准搜索），结果才准确；当模型陷入大量搜索循环时（36步 vs 21步），context 被大量不相关信息污染，最终给出错误答案。

### 3.3 典型失败模式

#### 失败模式1：自信地给出错误答案（Confident Wrong）
```
Q: I am looking for a hike to a specific scenic location...（多条件约束）
Gold: Trolltunga
Pred: Old Man of the Mountain (Profile Viewpoint) in Franconia Notch State Park, New Hampshire
```
模型找到了一个"满足部分条件"的答案就停止，缺乏严格的逐条验证。

#### 失败模式2：条件满足时间估算错误
```
Q: 一位诗人在民国时期出国留学...在某混战爆发后的第3年，他前往...之后的一年沿着哪条铁路？
Gold: 平绥铁路
Pred: 津浦铁路-陇海铁路（时间计算出错，且无法有效搜索民国历史长尾信息）
```

#### 失败模式3：多条件约束的幻觉（Hallucination Under Constraint）
```
Q: Person A matches: AMS Fellow (2006-2019) + PhD dissertation (topic X) + taught at...
Gold: Russell David Lyons
Pred: Alain-Sol Sznitman（满足部分条件但非答案）
```
模型倾向于找到一个"近似满足所有条件"的人，而非严格验证每个条件。

### 3.4 中文问题特有问题
- **Serper 搜索引擎对中文长尾历史/文化问题覆盖极差**：很多中文历史问题（如民国时期的铁路考察路线）完全搜不到相关内容
- **模型被迫"编造"答案**：搜索无果后，模型利用自身参数知识给出答案，但此类问题的正确答案超出了训练知识范围

---

## 4. 与 SWALM 的架构差异总结

| 特性 | SWALM | DAG-DeepResearch | 影响 |
|------|-------|-----------------|------|
| Context 压缩 | CascadedFIFOCondenser（限20条历史） | 无压缩，全量堆叠 | DAG 每步消耗 10倍+ tokens |
| 搜索引擎 | complex-mix-v1（混合搜索） | Google Serper | SWALM 搜索覆盖更全 |
| 验证机制 | use_force_answer=True | 无 | SWALM 有兜底 |
| 搜索次数控制 | 结构化规划后执行 | 散漫探索（平均49次/题） | 重复搜索浪费大量资源 |
| 中文搜索 | complex-mix-v1 可能含百度等 | 仅 Serper（英文为主） | 中文问题差距更大 |

---

## 5. 优化建议（按优先级排序）

### 🔴 高优先级

**1. 强制答案验证步骤（最重要）**
- 找到候选答案后，必须用独立的新查询交叉验证（至少2个不同来源）
- 对多条件约束问题，建立"验证清单"，逐条核查答案是否满足
- 期望效果：将"找到但答错"从80%降低到50%以下

**2. Context 压缩机制（CascadedFIFOCondenser）**
- 参考 SWALM 实现，限制历史搜索结果数量（如保留最近15条相关信息）
- 对搜索结果做结构化摘要（仅保留关键事实），而非全文堆叠
- 期望效果：将每题耗时从18.8min降至5min以内，同时提升答案质量（减少"信息迷失"）

**3. 增加中文搜索源**
- 为中文问题增加百度/必应中文作为备用搜索源
- 检测问题语言，自动选择最适合的搜索引擎
- 期望效果：bc_zh 准确率从21.7%提升至40%+

### 🟡 中优先级

**4. 搜索发散控制**
- 设置每个搜索目标的最大搜索次数（如每个子目标最多5次尝试）
- 失败后强制切换策略（扩展查询 → 换关键词 → 直接爬已知权威页面）
- 期望效果：将平均搜索次数从49次降至20次以内

**5. 早停机制**
- 当模型高置信度找到满足所有条件的答案，且已有多源验证时，立即终止搜索
- 避免继续搜索导致context中混入干扰信息

### 🟢 低优先级

**6. Planning 质量提升**
- 初始规划阶段为每个条件生成专属搜索策略（而非混合搜索）
- 对时间关联问题（"第X年之后"），先确定基准时间点再推导目标时间

**7. 答案格式化**
- 要求模型在 final_answer 中明确给出简洁答案（而非长段解释）
- 减少 judge 理解偏差

---

## 6. DSQ 评测说明

DeepSearchQA 仍在运行中（评测数据将在后续更新）。

从架构层面预测：
- DSQ 包含 Set Answer 类型（需要找到多个答案）
- DAG-DeepResearch 的多步搜索对 Set Answer 应有一定优势
- 预计 F1 在 0.2-0.35 之间（低于 SWALM 的 0.465）
